This is Anagha, and this is my attempt to explain what are Markov Chains. 
This is where I'm going to explain it. 

A Markov Chain is a model that outlines the statistical probability of a random process. They are mathematical systems that use a previous state to determine the probability distribution of the current state. 
Markov chains are made of two things: 
* A State Space 
* A Probability Transition Function 

Markov chains are often processes with the Markov property. The Markov property states that the probability distribution of future states depends only on the present state (also refered to as a memoryless random process). However this definition only really covers homogeneous discrete time Markov chains, there are also inhomogeneous Markov chains. 
